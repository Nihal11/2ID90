\documentclass[11pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\usepackage[linesnumbered,noend]{algorithm2e}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage{xcolor}
\hypersetup{ % Copied from: http://tex.stackexchange.com/a/847/41003
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

% New paragraph = blank line, not indent.
\setlength{\parskip}{0.3cm}
\setlength{\parindent}{0pt}

% Code listings
\usepackage{listings}
\usepackage{color,courier}

\definecolor{dkgreen}{rgb}{0,0.55,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{language=Python,
linewidth=80em,
breaklines=true,
numbers=left,
basicstyle=\ttfamily\footnotesize,
showstringspaces=false,
numberstyle=\tiny\color{gray},
keywordstyle=\color{blue},
commentstyle=\color{dkgreen},
stringstyle=\color{mauve},
}


\title{Spelling Correction}
\author{
Dennis van der Schagt (0814249)\\
Rob Wu (0787817)
}
\date{\today}


\begin{document}
\maketitle
\newpage
\section*{Abstract}


\section{The algorithm}
To find the best suggestion for a spelling correction, potential spelling corrections need to be generated and evaluated.

We assume that the input text contains at most two misspelled words, which are not next to each other.
To find the most appropriate spelling correction, we first rate the original text, and then re-evaluate the text with one or two words modified.
We apply the noisy channel model and assume that a word contains only one typographical mistake (insertion, deletion or substitution of one character, or transposition of two consecutive characters). For each input word, a list of such corrections is generated. These corrections are called \textit{candidates}. The output where words may be replaced by candidates is called a \textit{suggestion}.

To evaluate a suggestion, the likelihood of a candidate is used, as well as the likelihood of the bigrams of candidates within the suggestion.
These likelihoods are combined (the exact method is explained later) and form the \textit{combined likelihood}.
After calculating the likelihoods for every suggestion, the one with the maximal \textit{combined likelihood} is presented as the final suggestion for spelling correction.

\subsection{General flow}
A naive way to implement the previous concepts is to generate a list containing every possible suggestion, and then iterate over the list to find the maximal value.
Although this method is simple, it is not the best choice because it does not scale well: the number of suggestions is of the order $O(\textit{[number of candidates per word]}^2 \times \textit{[number of words in the input text]})$.
This excessive memory demand can be solved by immediately evaluating the suggestion when it is generated, and replacing the then-best suggestion with the just-evaluated suggestion when its combined likelihood is higher.

Suggestions are generated as follows. First, we split the input text into a list of words. Then, for each word, we generate and store a list of candidates (as elaborated in section \ref{generateCandidateWords}). This step requires $O(\textit{[number of candidates per word]} \times \textit{[number of words in the input text]})$ memory. If peak memory usage is a concern, this step can be omitted at the cost of speed (time) in the next step.

The actual suggestion generation is done by using the assumption that at most two non-consecutive errors occur in the input text. For every word, we iterate over the list of candidates and evaluate the suggestion that is equal to the original text, but with the given word replaced by a candidate. Similar logic is used to find and evaluate the second spelling error. The original word is also rated, since it is also possible that the input is correct, i.e. contains zero spelling errors.

The pseudo-code of the general structure is displayed below.

\begin{lstlisting}[language=python]
words = input.split(' ')
candidates = []
for word in words:
   # getCandidateWords generates a set of candidates for each word; its
   # exact implementation is explained later.
   candidates.append(getCandidateWords(word))

# The program will not output a suggestion if a word is not in the dictionary.
bestSuggestion = input if input in dictionary  else  ""

for error1 in range( 0, len(words) ):
    for candidate1 in candidates:
        # Evaluate the suggestion, with the word at position |error1| replaced
        # by |candidate1|.
        evaluate(error1, candidate1)
      
        # Try to find the next error. The next word after a corrected word is
        # assumed to be correct, so skip the word at the next position and
        # start iterating over the words from the next position, i.e. at
        # position |error1| + 2.
        for error2 in range( error1 + 2, len(words) ):

            for candidate2 in candidates:
                # Evaluate the suggestion, with the word at position |error2|
                # replaced with |candidate2|. Note that the word at position
                # |error1| is still |candidate1|.
                evaluate(error2, candidate2)
        
         # restore the original word at position |error2|, so that the next
         # iteration over |error1| will use the original word.
         restore(error2)

     # restore the original word at position |error1|
     restore(error1)

# At this point, every possible combination of candidates in the suggestion has
# been checked by the evaluate function, and the best suggestion has been
# selected. Show this suggestion.
print(bestSuggestion)
\end{lstlisting}

\subsection{Generating candidates}\label{generateCandidateWords}
As said before, we assume that a candidate differs from the original word by at most one modification, which is either a character insertion/deletion/substitution or a transposition of consecutive characters.
Each of these mutations are defined in terms of a range (start + end position) and replacement. A potential candidate is generated by replacing the characters within this range by the replacement. The potential candidate is only appended to the list of candidates if the it is in the dictionary.

%TODO show boring pseudo-code/explanation of how mutations are generated.

%TODO explain use of confusion matrix + summation of probabilities

%TODO Throw "channel model probability" term in the text.

%TODO Mention that the probability is tied to the word and position, and stored together with the candidate for performance reasons.

\subsection{Bigram language model probability}
\subsection{Generating suggestions}

\section{Results}

\section{Reproducing the results}
Following are the steps required to reproduce our results:
\begin{itemize}
\item Download the Netbeans project of our Spelling correction program from Peach.
\item Compile the project, e.g. using \textsc{ant compile}.
\item Run the project, e.g. using \textsc{ant run}.
\item Type a sentence consisting of lowercase Latin letters and spaces, with at most two spelling errors and press enter.
\item Read the result. The corrected sentence will be displayed as "Answer: [corrected sentence].
\end{itemize}

\section{References}


\section{Contributions}
Dennis and Rob contributed equally to this assignment.


\end{document}














